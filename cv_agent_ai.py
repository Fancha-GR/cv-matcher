import streamlit as st
import os
import docx
import PyPDF2
from dotenv import load_dotenv
from sklearn.metrics.pairwise import cosine_similarity
import openai
import numpy as np
import pandas as pd

# ğŸ” Î¦ÏŒÏÏ„Ï‰ÏƒÎ· OpenAI API Key
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# ğŸ§¾ Î¤Î¯Ï„Î»Î¿Ï‚ + Î”Î®Î»Ï‰ÏƒÎ· Î±Ï€Î¿ÏÏÎ®Ï„Î¿Ï…
st.title("ğŸ¤– CV Matcher Î¼Îµ OpenAI Embeddings")

st.info("""
ğŸ”’ **Î Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Î‘ÏƒÏ†Î±Î»ÎµÎ¯Î±Ï‚ / Î ÏÎ¿ÏƒÏ„Î±ÏƒÎ¯Î±Ï‚ Î ÏÎ¿ÏƒÏ‰Ï€Î¹ÎºÏÎ½ Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½**

Î— Ï€Î±ÏÎ¿ÏÏƒÎ± ÎµÏ†Î±ÏÎ¼Î¿Î³Î® Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯ Ï„Î·Î½ Ï€Î»Î±Ï„Ï†ÏŒÏÎ¼Î± Streamlit Î³Î¹Î± Ï„Î·Î½ Î±Î½Î¬Î»Ï…ÏƒÎ· Î²Î¹Î¿Î³ÏÎ±Ï†Î¹ÎºÏÎ½ (CV) Ï„Î¿Ï€Î¹ÎºÎ¬, Ï‡Ï‰ÏÎ¯Ï‚ Î±Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½.

âœ… Î¤Î± Î±ÏÏ‡ÎµÎ¯Î± Ï€Î¿Ï… Î±Î½ÎµÎ²Î¬Î¶ÎµÏ„Îµ (PDF, DOCX, TXT):
- **Î”Î•Î Î±Ï€Î¿Î¸Î·ÎºÎµÏÎ¿Î½Ï„Î±Î¹** ÏƒÏ„Î¿ cloud Î® ÏƒÎµ ÎºÎ¬Ï€Î¿Î¹Î¿Î½ Î´Î¹Î±ÎºÎ¿Î¼Î¹ÏƒÏ„Î®.
- **Î”Î•Î ÎºÎ¿Î¹Î½Î¿Ï€Î¿Î¹Î¿ÏÎ½Ï„Î±Î¹** ÏƒÎµ Ï„ÏÎ¯Ï„Î¿Ï…Ï‚.
- **Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ½Ï„Î±Î¹ Î¼ÏŒÎ½Î¿ Ï€ÏÎ¿ÏƒÏ‰ÏÎ¹Î½Î¬** Î³Î¹Î± Ï„Î·Î½ ÎµÎºÏ„Î­Î»ÎµÏƒÎ· Ï„Î·Ï‚ Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·Ï‚.

ğŸ§  Î— Î±Î½Î¬Î»Ï…ÏƒÎ· Î³Î¯Î½ÎµÏ„Î±Î¹ Î¼Îµ Ï‡ÏÎ®ÏƒÎ· Ï„Î¿Ï… GPT API Ï„Î·Ï‚ OpenAI, ÎºÎ±Î¹ Ï„Î¿ Ï€ÎµÏÎ¹ÎµÏ‡ÏŒÎ¼ÎµÎ½Î¿ Î±Ï€Î¿ÏƒÏ„Î­Î»Î»ÎµÏ„Î±Î¹ ÎºÏÏ…Ï€Ï„Î¿Î³ÏÎ±Ï†Î·Î¼Î­Î½Î± ÎºÎ±Î¹ Î¼ÏŒÎ½Î¿ Î³Î¹Î± Ï„Î·Î½ Ï€Î±ÏÎ¿Ï‡Î® Î±Ï€Î¬Î½Ï„Î·ÏƒÎ·Ï‚.

ğŸ•’ ÎœÎµÏ„Î¬ Ï„Î· Î»Î®Î¾Î· Ï„Î·Ï‚ ÏƒÏ…Î½ÎµÎ´ÏÎ¯Î±Ï‚ (Ï€.Ï‡. Î±Î½ ÎºÎ»ÎµÎ¯ÏƒÎµÏ„Îµ Ï„Î· ÏƒÎµÎ»Î¯Î´Î±), ÏŒÎ»Î± Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î´Î¹Î±Î³ÏÎ¬Ï†Î¿Î½Ï„Î±Î¹ Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î± Î±Ï€ÏŒ Ï„Î· Î¼Î½Î®Î¼Î·.
""")

# ğŸ“¤ Upload CVs
uploaded_files = st.file_uploader("ğŸ“¤ Î‘Î½Î­Î²Î±ÏƒÎµ Î­Ï‰Ï‚ 20 Î²Î¹Î¿Î³ÏÎ±Ï†Î¹ÎºÎ¬ (PDF, DOCX, TXT)", accept_multiple_files=True, type=["pdf", "txt", "docx"])

# ğŸ“ Î ÎµÏÎ¹Î³ÏÎ±Ï†Î® ÎºÎ±Î¹ ÎµÏÏÏ„Î·ÏƒÎ·
job_description = st.text_area("ğŸ“ Î ÎµÏÎ¹Î³ÏÎ±Ï†Î® Î˜Î­ÏƒÎ·Ï‚", placeholder="Î .Ï‡. ÎœÎ·Ï‡Î±Î½Î¹ÎºÏŒÏ‚ Î¤Î·Î»ÎµÏ€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î¹ÏÎ½ Î¼Îµ ÎµÎ¼Ï€ÎµÎ¹ÏÎ¯Î± ÏƒÎµ AutoCAD ÎºÎ±Î¹ ÎŸÏ€Ï„Î¹ÎºÎ­Ï‚ ÎŠÎ½ÎµÏ‚")
user_question = st.text_input("ğŸ¤” Î¡ÏÏ„Î·ÏƒÎµ ÎºÎ¬Ï„Î¹ Î³Î¹Î± Ï„Î± CV (Ï€.Ï‡. 'Ï€Î¿Î¹Î¿Ï‚ Î­Ï‡ÎµÎ¹ ÎµÎ¼Ï€ÎµÎ¹ÏÎ¯Î± ÏƒÎµ AutoCAD;')")

# ğŸ“ ÎšÎ¿Ï…Î¼Ï€Î¯ Î¥Ï€Î¿Î²Î¿Î»Î®Ï‚
submitted = st.button("ğŸ” Î‘Î½Î¬Î»Ï…ÏƒÎ· Î’Î¹Î¿Î³ÏÎ±Ï†Î¹ÎºÏÎ½")

# âš ï¸ ÎŒÏÎ¹Î¿ 20 Î±ÏÏ‡ÎµÎ¯Ï‰Î½
if uploaded_files and len(uploaded_files) > 20:
    st.warning("âš ï¸ ÎœÏ€Î¿ÏÎµÎ¯Ï„Îµ Î½Î± Î±Î½ÎµÎ²Î¬ÏƒÎµÏ„Îµ Î­Ï‰Ï‚ 20 Î±ÏÏ‡ÎµÎ¯Î± ÎºÎ¬Î¸Îµ Ï†Î¿ÏÎ¬.")
    st.stop()


def extract_text(file):
    if file.type == "application/pdf":
        reader = PyPDF2.PdfReader(file)
        return "\n".join([page.extract_text() or "" for page in reader.pages])
    elif file.type == "text/plain":
        return str(file.read(), "utf-8")
    elif file.type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
        doc = docx.Document(file)
        return "\n".join([para.text for para in doc.paragraphs])
    return ""


def get_embedding(text):
    response = openai.embeddings.create(
        input=text,
        model="text-embedding-3-small"
    )
    return np.array(response.data[0].embedding)


# ğŸš€ Î‘Î½Î¬Î»Ï…ÏƒÎ· Î¼ÏŒÎ½Î¿ ÏŒÏ„Î±Î½ Ï€Î±Ï„Î·Î¸ÎµÎ¯ Ï„Î¿ ÎºÎ¿Ï…Î¼Ï€Î¯
if submitted and uploaded_files and job_description:
    with st.spinner("ğŸ” Î“Î¯Î½ÎµÏ„Î±Î¹ Î±Î½Î¬Î»Ï…ÏƒÎ·..."):
        job_embed = get_embedding(job_description)

        results = []
        for file in uploaded_files:
            content = extract_text(file)
            if content.strip() == "":
                continue
            cv_embed = get_embedding(content[:3000])  # OpenAI limit
            similarity = cosine_similarity([job_embed], [cv_embed])[0][0]
            results.append((file.name, similarity))

        sorted_results = sorted(results, key=lambda x: x[1], reverse=True)

        # ğŸ”½ Î•Î¾Î±Î³Ï‰Î³Î® ÏƒÎµ CSV
        if sorted_results:
            export_data = []
            for name, score in sorted_results:
                row = {"ÎŒÎ½Î¿Î¼Î± Î±ÏÏ‡ÎµÎ¯Î¿Ï…": name, "Î£ÎºÎ¿Ï Î¤Î±ÏÏ„Î¹ÏƒÎ·Ï‚ (%)": round(score * 100, 2)}
                export_data.append(row)

            df = pd.DataFrame(export_data)
            csv = df.to_csv(index=False).encode('utf-8')

            st.download_button(
                label="ğŸ’¾ Î•Î¾Î±Î³Ï‰Î³Î® Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½ ÏƒÎµ CSV",
                data=csv,
                file_name='cv_match_results.csv',
                mime='text/csv',
            )

        # ğŸ“Š Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½
        st.subheader("ğŸ“Š ÎšÎ±Ï„Î¬Ï„Î±Î¾Î· Ï…Ï€Î¿ÏˆÎ·Ï†Î¯Ï‰Î½:")
        for name, score in sorted_results:
            st.markdown(f"### ğŸ“„ {name}")
            st.markdown(f"**Î£ÎºÎ¿Ï Î¤Î±ÏÏ„Î¹ÏƒÎ·Ï‚:** {round(score * 100, 2)}%")

            for file in uploaded_files:
                if file.name == name:
                    content = extract_text(file)

                    if user_question:
                        with st.spinner(f"ğŸ¤– Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± ÎµÏÏÏ„Î·ÏƒÎ·Ï‚ Î³Î¹Î± {name}..."):
                            response = openai.chat.completions.create(
                                model="gpt-3.5-turbo",
                                messages=[
                                    {"role": "system", "content": "Î•Î¯ÏƒÎ±Î¹ Î²Î¿Î·Î¸ÏŒÏ‚ Ï€ÏÏŒÏƒÎ»Î·ÏˆÎ·Ï‚. Î”ÏÏƒÎµ ÏƒÏÎ½Ï„Î¿Î¼Î· Î±Ï€Î¬Î½Ï„Î·ÏƒÎ· Î½Î±Î¹ Î® ÏŒÏ‡Î¹."},
                                    {"role": "user", "content": f"Î‘ÎºÎ¿Î»Î¿Ï…Î¸ÎµÎ¯ Î­Î½Î± Î²Î¹Î¿Î³ÏÎ±Ï†Î¹ÎºÏŒ:\n{content[:3000]}\n\nÎ•ÏÏÏ„Î·ÏƒÎ·: {user_question}"}
                                ]
                            )
                            reply = response.choices[0].message.content.strip()
                            st.info(f"GPT: {reply}")

                    st.expander("ğŸ“– Î”ÎµÏ‚ Ï€ÎµÏÎ¹ÎµÏ‡ÏŒÎ¼ÎµÎ½Î¿ Î²Î¹Î¿Î³ÏÎ±Ï†Î¹ÎºÎ¿Ï").write(content[:2000])
                    break
