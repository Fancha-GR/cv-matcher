import streamlit as st
import os
import docx
import PyPDF2
from dotenv import load_dotenv
from sklearn.metrics.pairwise import cosine_similarity
import openai
import numpy as np
import pandas as pd

load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

st.title("ğŸ¤– CV Matcher Î¼Îµ OpenAI Embeddings")

uploaded_files = st.file_uploader("ğŸ“¤ Î‘Î½Î­Î²Î±ÏƒÎµ Î²Î¹Î¿Î³ÏÎ±Ï†Î¹ÎºÎ¬ (PDF, DOCX, TXT)", accept_multiple_files=True, type=["pdf", "txt", "docx"])

job_description = st.text_area("ğŸ“ Î ÎµÏÎ¹Î³ÏÎ±Ï†Î® Î˜Î­ÏƒÎ·Ï‚", placeholder="Î .Ï‡. ÎœÎ·Ï‡Î±Î½Î¹ÎºÏŒÏ‚ Î¤Î·Î»ÎµÏ€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î¹ÏÎ½ Î¼Îµ ÎµÎ¼Ï€ÎµÎ¹ÏÎ¯Î± ÏƒÎµ AutoCAD ÎºÎ±Î¹ ÎŸÏ€Ï„Î¹ÎºÎ­Ï‚ ÎŠÎ½ÎµÏ‚")
user_question = st.text_input("ğŸ¤” Î¡ÏÏ„Î·ÏƒÎµ ÎºÎ¬Ï„Î¹ Î³Î¹Î± Ï„Î± CV (Ï€.Ï‡. 'Ï€Î¿Î¹Î¿Ï‚ Î­Ï‡ÎµÎ¹ ÎµÎ¼Ï€ÎµÎ¹ÏÎ¯Î± ÏƒÎµ AutoCAD;')")


def extract_text(file):
    if file.type == "application/pdf":
        reader = PyPDF2.PdfReader(file)
        return "\n".join([page.extract_text() or "" for page in reader.pages])
    elif file.type == "text/plain":
        return str(file.read(), "utf-8")
    elif file.type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
        doc = docx.Document(file)
        return "\n".join([para.text for para in doc.paragraphs])
    return ""


def get_embedding(text):
    response = openai.embeddings.create(
        input=text,
        model="text-embedding-3-small"
    )
    return np.array(response.data[0].embedding)


if uploaded_files and job_description:
    with st.spinner("ğŸ” Î“Î¯Î½ÎµÏ„Î±Î¹ Î±Î½Î¬Î»Ï…ÏƒÎ·..."):
        job_embed = get_embedding(job_description)

        results = []
        for file in uploaded_files:
            content = extract_text(file)
            if content.strip() == "":
                continue
            cv_embed = get_embedding(content[:3000])  # OpenAI limit
            similarity = cosine_similarity([job_embed], [cv_embed])[0][0]
            results.append((file.name, similarity))

        sorted_results = sorted(results, key=lambda x: x[1], reverse=True)

        # ğŸ”½ Î•Î¾Î±Î³Ï‰Î³Î® ÏƒÎµ CSV
        if sorted_results:
            export_data = []
            for name, score in sorted_results:
                row = {"ÎŒÎ½Î¿Î¼Î± Î±ÏÏ‡ÎµÎ¯Î¿Ï…": name, "Î£ÎºÎ¿Ï Î¤Î±ÏÏ„Î¹ÏƒÎ·Ï‚ (%)": round(score * 100, 2)}
                export_data.append(row)

            df = pd.DataFrame(export_data)

            csv = df.to_csv(index=False).encode('utf-8')

            st.download_button(
                label="ğŸ’¾ Î•Î¾Î±Î³Ï‰Î³Î® Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½ ÏƒÎµ CSV",
                data=csv,
                file_name='cv_match_results.csv',
                mime='text/csv',
            )

        st.subheader("ğŸ“Š ÎšÎ±Ï„Î¬Ï„Î±Î¾Î· Ï…Ï€Î¿ÏˆÎ·Ï†Î¯Ï‰Î½:")
        for name, score in sorted_results:
            st.markdown(f"### ğŸ“„ {name}")
            st.markdown(f"**Î£ÎºÎ¿Ï Î¤Î±ÏÏ„Î¹ÏƒÎ·Ï‚:** {round(score * 100, 2)}%")

            # Î‘Î½Î¬Î»Ï…ÏƒÎ· GPT
            for file in uploaded_files:
                if file.name == name:
                    content = extract_text(file)

                    if user_question:
                        with st.spinner(f"ğŸ¤– Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± ÎµÏÏÏ„Î·ÏƒÎ·Ï‚ Î³Î¹Î± {name}..."):
                            response = openai.chat.completions.create(
                                model="gpt-3.5-turbo",
                                messages=[
                                    {"role": "system", "content": "Î•Î¯ÏƒÎ±Î¹ Î²Î¿Î·Î¸ÏŒÏ‚ Ï€ÏÏŒÏƒÎ»Î·ÏˆÎ·Ï‚. Î”ÏÏƒÎµ ÏƒÏÎ½Ï„Î¿Î¼Î· Î±Ï€Î¬Î½Ï„Î·ÏƒÎ· Î½Î±Î¹ Î® ÏŒÏ‡Î¹."},
                                    {"role": "user", "content": f"Î‘ÎºÎ¿Î»Î¿Ï…Î¸ÎµÎ¯ Î­Î½Î± Î²Î¹Î¿Î³ÏÎ±Ï†Î¹ÎºÏŒ:\n{content[:3000]}\n\nÎ•ÏÏÏ„Î·ÏƒÎ·: {user_question}"}
                                ]
                            )
                            reply = response.choices[0].message.content.strip()
                            st.info(f"GPT: {reply}")

                    st.expander("ğŸ“– Î”ÎµÏ‚ Ï€ÎµÏÎ¹ÎµÏ‡ÏŒÎ¼ÎµÎ½Î¿ Î²Î¹Î¿Î³ÏÎ±Ï†Î¹ÎºÎ¿Ï").write(content[:2000])
                    break
